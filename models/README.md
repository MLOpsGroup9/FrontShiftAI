# Models Folder
Place your quantized LLaMA 3 GGUF models here.  
Example: `llama-3-8b-instruct-q4_k_m.gguf` (download from Hugging Face).
