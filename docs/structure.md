GitHub Repo Structure for FrontShiftAI PLANNED 

```bash
FrontShiftAI/
â”‚
â”œâ”€â”€ data/                     # Raw and processed data
â”‚   â”œâ”€â”€ raw/                  # Original PDFs (handbooks, FAQs)
â”‚   â”œâ”€â”€ processed/             # Cleaned text, chunks
â”‚   â””â”€â”€ qna/                  # Final Q&A dataset (CSV, JSONL)
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_text_extraction.ipynb
â”‚   â”œâ”€â”€ 02_chunking_cleaning.ipynb
â”‚   â”œâ”€â”€ 03_qna_generation.ipynb
â”‚   â”œâ”€â”€ 04_embedding_experiments.ipynb
â”‚   â””â”€â”€ 05_eval_metrics.ipynb
â”‚
â”œâ”€â”€ src/                      # Core source code
â”‚   â”œâ”€â”€ rag/                  # Retrieval-Augmented Generation
â”‚   â”‚   â”œâ”€â”€ ingest.py          # PDF â†’ text ingestion
â”‚   â”‚   â”œâ”€â”€ chunking.py        # Semantic chunking
â”‚   â”‚   â”œâ”€â”€ embed.py           # Embeddings + vector DB indexing
â”‚   â”‚   â”œâ”€â”€ retriever.py       # Hybrid/dense retrieval
â”‚   â”‚   â””â”€â”€ qa_pipeline.py     # RAG Q&A pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/               # Agentic orchestration
â”‚   â”‚   â”œâ”€â”€ tools/             # Tool wrappers (calendar, LMS, HRIS)
â”‚   â”‚   â”œâ”€â”€ memory.py          # Context + conversation memory
â”‚   â”‚   â””â”€â”€ orchestrator.py    # Agent logic
â”‚   â”‚
â”‚   â”œâ”€â”€ voice/                # Voice interaction
â”‚   â”‚   â”œâ”€â”€ stt.py             # Speech-to-text (Whisper/GCP STT)
â”‚   â”‚   â”œâ”€â”€ tts.py             # Text-to-speech (Coqui/GCP TTS)
â”‚   â”‚   â””â”€â”€ voice_agent.py     # Voice-enabled agent wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                  # Backend API
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI entrypoint
â”‚   â”‚   â”œâ”€â”€ routes/            # Endpoints for chat, RAG, agents
â”‚   â”‚   â””â”€â”€ schemas.py         # Request/response schemas
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # Helpers
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ infra/                    # Deployment & infra
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ k8s/                   # Kubernetes manifests
â”‚   â”œâ”€â”€ gcp/                   # Vertex AI / GCP configs
â”‚   â””â”€â”€ ci-cd/                 # GitHub Actions / Cloud Build
â”‚
â”œâ”€â”€ tests/                    # Unit & integration tests
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_voice.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ Project_Scoping.md
â”‚   â”œâ”€â”€ README_assets/         # Images/diagrams for docs
â”‚   â”œâ”€â”€ system_architecture.png
â”‚   â””â”€â”€ deployment_flow.png
â”‚
â”œâ”€â”€ README.md                 # High-level overview
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ environment.yml           # Conda environment (optional)
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```


Updated Repo Structure (with Data Pipeline clear)
```bash
FrontShiftAI/
â”‚
â”œâ”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ raw/                  # Original PDFs (handbooks, FAQs)
â”‚   â”œâ”€â”€ processed/             # Cleaned text, structured chunks
â”‚   â””â”€â”€ qna/                  # Final Q&A dataset (CSV, JSONL)
â”‚
â”œâ”€â”€ data_pipeline/            # ðŸš€ Data pipeline modules
â”‚   â”œâ”€â”€ extract_text.py        # PDF â†’ raw text
â”‚   â”œâ”€â”€ clean_text.py          # Normalize (remove headers, dupes, artifacts)
â”‚   â”œâ”€â”€ chunk_text.py          # Split into semantic chunks
â”‚   â”œâ”€â”€ generate_qna.py        # Synthetic Q&A generation (optional)
â”‚   â”œâ”€â”€ embed_index.py         # Embedding + vector DB indexing
â”‚   â””â”€â”€ pipeline_runner.py     # Orchestrates full ETL pipeline
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ 01_text_extraction.ipynb
â”‚   â”œâ”€â”€ 02_chunking_cleaning.ipynb
â”‚   â”œâ”€â”€ 03_qna_generation.ipynb
â”‚   â”œâ”€â”€ 04_embedding_experiments.ipynb
â”‚   â””â”€â”€ 05_eval_metrics.ipynb
â”‚
â”œâ”€â”€ src/                      # Core application code
â”‚   â”œâ”€â”€ rag/                  # Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ agents/               # Agentic orchestration
â”‚   â”œâ”€â”€ voice/                # STT/TTS integrations
â”‚   â”œâ”€â”€ api/                  # FastAPI backend
â”‚   â””â”€â”€ utils/                 # Shared helpers
â”‚
â”œâ”€â”€ infra/                    # Deployment & infra (Docker, GCP, K8s, CI/CD)
â”œâ”€â”€ tests/                    # Unit & integration tests
â”œâ”€â”€ docs/                     # Project_Scoping, diagrams, assets
â”œâ”€â”€ README.md                 # High-level overview
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```



Extended Project Structure (with Fine-Tuning)
```bash
FrontShiftAI/
â”‚
â”œâ”€â”€ data/                         
â”‚   â”œâ”€â”€ raw/                      # Original PDFs (handbooks, FAQs)
â”‚   â”œâ”€â”€ processed/                 # Cleaned text, structured chunks
â”‚   â”œâ”€â”€ qna/                       # Final Q&A dataset (JSONL/CSV)
â”‚   â”‚   â”œâ”€â”€ qa.jsonl               # 1k Q&A pairs (context + no-context)
â”‚   â”‚   â”œâ”€â”€ train.jsonl            # Training split
â”‚   â”‚   â”œâ”€â”€ val.jsonl              # Validation split
â”‚   â”‚   â””â”€â”€ test.jsonl             # Test split
â”‚
â”œâ”€â”€ data_pipeline/                 # (Optional) ETL pipeline scripts
â”‚   â”œâ”€â”€ extract_text.py
â”‚   â”œâ”€â”€ clean_text.py
â”‚   â”œâ”€â”€ chunk_text.py
â”‚   â”œâ”€â”€ generate_qna.py
â”‚   â”œâ”€â”€ embed_index.py
â”‚   â””â”€â”€ pipeline_runner.py
â”‚
â”œâ”€â”€ src/                          
â”‚   â”œâ”€â”€ rag/                       # Retrieval-Augmented Generation
â”‚   â”‚   â”œâ”€â”€ embed.py               # Build Chroma index
â”‚   â”‚   â”œâ”€â”€ qa_pipeline.py         # RAG Q&A system
â”‚   â”‚   â””â”€â”€ eval_rag.py            # Evaluate Recall@k, F1, hallucination
â”‚   â”‚
â”‚   â”œâ”€â”€ finetune/                  # Fine-tuning module
â”‚   â”‚   â”œâ”€â”€ prepare_data.py        # Convert Q&A dataset into instruct format
â”‚   â”‚   â”œâ”€â”€ train_lora.py          # Fine-tune LLaMA-3 8B with LoRA/QLoRA
â”‚   â”‚   â”œâ”€â”€ evaluate_ft.py         # Evaluate fine-tuned model
â”‚   â”‚   â””â”€â”€ inference_ft.py        # Run inference with fine-tuned model
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                    # Agentic orchestration
â”‚   â”‚   â”œâ”€â”€ tools/                 # Calendar/LMS/HRIS tool wrappers
â”‚   â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”‚   â””â”€â”€ memory.py
â”‚   â”‚
â”‚   â”œâ”€â”€ voice/                     # Voice STT/TTS integration
â”‚   â”‚   â”œâ”€â”€ stt.py
â”‚   â”‚   â”œâ”€â”€ tts.py
â”‚   â”‚   â””â”€â”€ voice_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                       # Backend API
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPI entrypoint
â”‚   â”‚   â””â”€â”€ routes/                # Endpoints (rag, agents, voice)
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     
â”‚       â”œâ”€â”€ config.py              # Model/DB settings
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ infra/                         # Deployment & infra
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ k8s/                       # Kubernetes manifests
â”‚   â””â”€â”€ gcp/                       # Vertex AI / GKE configs
â”‚
â”œâ”€â”€ tests/                         # Unit & integration tests
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â”œâ”€â”€ test_finetune.py
â”‚   â”œâ”€â”€ test_agents.py              # Placeholder for agents
â”‚   â”œâ”€â”€ test_voice.py               # Placeholder for voice
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ Project_Scoping.md
â”‚   â”œâ”€â”€ README_assets/
â”‚   â””â”€â”€ diagrams/
â”‚
â”œâ”€â”€ models
â”œâ”€â”€ README.md                      # High-level overview
â”œâ”€â”€ requirements.txt               # Python deps (RAG + FT)
â”œâ”€â”€ environment.yml                 # Conda env (optional)
â””â”€â”€ LICENSE
```