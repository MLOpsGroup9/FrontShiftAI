from pathlib import Path
from data_pipeline.scripts.pdf_parser import MarkdownPDFExtractor
from data_pipeline.scripts.preprocess import main as preprocess_main

def get_any_pdf():
    raw_dir = Path("data/raw")  # ✅ fixed path
    pdf_files = list(raw_dir.glob("*.pdf"))
    assert pdf_files, f"No PDF files found in {raw_dir.resolve()}"
    return str(pdf_files[0])

def test_full_pipeline_flow():
    pdf_path = get_any_pdf()
    extractor = MarkdownPDFExtractor(pdf_path)
    extractor.extract()

    parsed_dir = Path("data/parsed")  # ✅ fixed
    md_files = list(parsed_dir.glob("*.md"))
    assert md_files, "No markdown files generated by pdf_parser"

    preprocess_main()

    cleaned_dir = Path("data/cleaned")  # ✅ fixed
    cleaned_files = list(cleaned_dir.glob("*.json"))
    assert cleaned_files, "No cleaned JSON files generated after preprocessing"
