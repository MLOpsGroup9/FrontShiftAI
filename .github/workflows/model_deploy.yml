# Standalone deployment workflow
# Can be called from other workflows or triggered manually
# Useful for deploying specific model versions or testing deployment process

name: Model Deploy - Standalone Deployment Workflow

on:
  workflow_call:
    inputs:
      model_path:
        description: 'Path to model file (optional)'
        required: false
        type: string
      quality_gate_status:
        description: 'Quality gate status'
        required: false
        type: string
        default: 'PASS'
  workflow_dispatch:
    inputs:
      model_path:
        description: 'Path to model file (optional)'
        required: false
        type: string
      quality_gate_status:
        description: 'Quality gate status'
        required: false
        type: string
        default: 'PASS'

jobs:
  pre-deployment-validation:
    name: Pre-deployment Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Verify Model File Integrity
        run: |
          MODEL_PATH="${{ inputs.model_path }}"
          if [ -z "$MODEL_PATH" ]; then
            MODEL_PATH="models/Llama-3.2-3B-Instruct-Q4_K_S.gguf"
          fi
          
          if [ ! -f "$MODEL_PATH" ]; then
            echo "❌ Model file not found: $MODEL_PATH"
            exit 1
          fi
          
          SIZE_MB=$(du -m "$MODEL_PATH" | cut -f1)
          echo "✅ Model file validated: $MODEL_PATH ($SIZE_MB MB)"
          echo "model_path=$MODEL_PATH" >> $GITHUB_ENV

      - name: Test Model Loading (if applicable)
        run: |
          echo "⚠️ Model inference test skipped (requires model-specific implementation)"
          # In a real scenario, you would load the model and test inference here
          # For GGUF models, this might require llama.cpp or similar
        continue-on-error: true

  deploy-to-registry:
    name: Deploy to Registry
    runs-on: ubuntu-latest
    needs: pre-deployment-validation
    timeout-minutes: 10

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Download Evaluation Artifacts (if available)
        uses: actions/download-artifact@v4
        with:
          name: eval-results
          path: .
        continue-on-error: true

      - name: Deploy Model to Registry
        run: |
          MODEL_PATH="${{ inputs.model_path }}"
          QG_STATUS="${{ inputs.quality_gate_status }}"
          
          if [ -z "$MODEL_PATH" ]; then
            python ml_pipeline/ci_cd/deploy_model.py \
              --quality-gate-status "$QG_STATUS"
          else
            python ml_pipeline/ci_cd/deploy_model.py \
              --model-path "$MODEL_PATH" \
              --quality-gate-status "$QG_STATUS"
          fi

      - name: Upload Model Registry
        uses: actions/upload-artifact@v4
        with:
          name: model-registry
          path: models_registry/
          retention-days: 90

  post-deployment-smoke-test:
    name: Post-deployment Smoke Test
    runs-on: ubuntu-latest
    needs: deploy-to-registry
    timeout-minutes: 5

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Download Model Registry
        uses: actions/download-artifact@v4
        with:
          name: model-registry
          path: models_registry/

      - name: Verify Deployed Model
        run: |
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          registry_dir = Path("models_registry")
          latest_path = registry_dir / "latest"
          
          # Find latest version
          if latest_path.exists():
              if latest_path.is_symlink():
                  version_dir = latest_path.resolve()
              else:
                  # Windows: read from file
                  with open(latest_path, 'r') as f:
                      version_dir = Path(f.read().strip())
              
              metadata_path = version_dir / "metadata.json"
              if metadata_path.exists():
                  with open(metadata_path, 'r') as f:
                      metadata = json.load(f)
                  print(f"✅ Deployed model verified:")
                  print(f"   Version: {metadata.get('version')}")
                  print(f"   Model: {metadata.get('model_name')}")
                  print(f"   Metrics: {metadata.get('metrics', {})}")
              else:
                  print("⚠️ Metadata not found")
          else:
              print("⚠️ Latest symlink not found")
          EOF

      - name: Run Sample Queries (if RAG available)
        run: |
          echo "⚠️ Sample query test skipped (requires ChromaDB in CI)"
          # In a real scenario, you would run 3 sample queries against the deployed model
        continue-on-error: true

