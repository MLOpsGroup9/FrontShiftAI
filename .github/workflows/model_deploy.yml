# Standalone deployment workflow
# Can be called from other workflows or triggered manually
# Useful for deploying specific model versions or testing deployment process

name: Model Deploy - Standalone Deployment Workflow

on:
  workflow_call:
    inputs:
      model_path:
        description: 'Path to model file (optional)'
        required: false
        type: string
      model_name:
        description: 'Logical model name to use inside the registry'
        required: false
        type: string
        default: 'frontshift-rag'
      evaluation_artifact_name:
        description: 'Name of the artifact that contains chat_pipeline/results and models'
        required: false
        type: string
        default: 'core-eval-results'
      quality_gate_status:
        description: 'Quality gate status'
        required: false
        type: string
        default: 'AUTO'
  workflow_dispatch:
    inputs:
      model_path:
        description: 'Path to model file (optional)'
        required: false
        type: string
      model_name:
        description: 'Logical model name to use inside the registry'
        required: false
        type: string
        default: 'frontshift-rag'
      evaluation_artifact_name:
        description: 'Name of the artifact that contains chat_pipeline/results and models'
        required: false
        type: string
        default: 'core-eval-results'
      quality_gate_status:
        description: 'Quality gate status'
        required: false
        type: string
        default: 'AUTO'

jobs:
  pre-deployment-validation:
    name: Pre-deployment Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Download Evaluation + Model Artifacts (optional)
        if: ${{ inputs.evaluation_artifact_name != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.evaluation_artifact_name }}
          path: .
        continue-on-error: true

      - name: Verify Model File Integrity
        run: |
          MODEL_PATH="${{ inputs.model_path }}"
          if [ -z "$MODEL_PATH" ]; then
            MODEL_PATH="models/Llama-3.2-3B-Instruct-Q4_K_S.gguf"
          fi
          
          if [ ! -f "$MODEL_PATH" ]; then
            echo "❌ Model file not found: $MODEL_PATH"
            exit 1
          fi
          
          SIZE_MB=$(du -m "$MODEL_PATH" | cut -f1)
          echo "✅ Model file validated: $MODEL_PATH ($SIZE_MB MB)"
          echo "model_path=$MODEL_PATH" >> $GITHUB_ENV

      - name: Test Model Loading (if applicable)
        run: |
          echo "⚠️ Model inference test skipped (requires model-specific implementation)"
          # In a real scenario, you would load the model and test inference here
          # For GGUF models, this might require llama.cpp or similar
        continue-on-error: true

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: pre-deployment-validation
    timeout-minutes: 10
    outputs:
      status: ${{ steps.quality_gate_result.outputs.status }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Download Evaluation Artifacts (if available)
        if: ${{ inputs.evaluation_artifact_name != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.evaluation_artifact_name }}
          path: .
        continue-on-error: true

      - name: Compute Quality Gate
        id: compute_quality_gate
        if: ${{ inputs.quality_gate_status == 'AUTO' }}
        run: |
          python -m chat_pipeline.tracking.compute_quality_gate
          STATUS=$(cat chat_pipeline/results/quality_gate.txt)
          echo "status=$STATUS" >> $GITHUB_OUTPUT

      - name: Finalize Quality Gate Status
        id: quality_gate_result
        run: |
          STATUS="${{ steps.compute_quality_gate.outputs.status }}"
          INPUT_STATUS="${{ inputs.quality_gate_status }}"
          if [ "$INPUT_STATUS" != "AUTO" ] && [ -n "$INPUT_STATUS" ]; then
            STATUS="$INPUT_STATUS"
          fi
          STATUS=$(echo "$STATUS" | tr '[:lower:]' '[:upper:]')
          if [ -z "$STATUS" ]; then
            echo "Quality gate status could not be determined."
            exit 1
          fi
          echo "Resolved quality gate status: $STATUS"
          echo "status=$STATUS" >> $GITHUB_OUTPUT

  deploy-to-registry:
    name: Deploy to Registry
    runs-on: ubuntu-latest
    needs:
      - pre-deployment-validation
      - quality-gate
    timeout-minutes: 10

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Download Evaluation Artifacts (if available)
        if: ${{ inputs.evaluation_artifact_name != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.evaluation_artifact_name }}
          path: .
        continue-on-error: true

      - name: Deploy Model to Registry
        env:
          QUALITY_GATE_STATUS: ${{ needs.quality-gate.outputs.status }}
        run: |
          MODEL_PATH="${{ inputs.model_path }}"
          if [ -z "$MODEL_PATH" ]; then
            MODEL_PATH="models/Llama-3.2-3B-Instruct-Q4_K_S.gguf"
          fi

          echo "Deploying model '${{ inputs.model_name }}' with quality gate status ${QUALITY_GATE_STATUS}"

          python -m chat_pipeline.tracking.deploy_model \
            --model-path "$MODEL_PATH" \
            --model-name "${{ inputs.model_name }}" \
            --quality-gate-status "$QUALITY_GATE_STATUS" \
            --metadata-output "models_registry/metadata_last_push.json"

      - name: Upload Model Registry
        uses: actions/upload-artifact@v4
        with:
          name: model-registry
          path: models_registry/
          retention-days: 90

  post-deployment-smoke-test:
    name: Post-deployment Smoke Test
    runs-on: ubuntu-latest
    needs: deploy-to-registry
    timeout-minutes: 5

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Environment Variables
        run: |
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        shell: bash

      - name: Download Model Registry
        uses: actions/download-artifact@v4
        with:
          name: model-registry
          path: models_registry/

      - name: Verify Deployed Model
        run: |
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          registry_dir = Path("models_registry")
          latest_path = registry_dir / "latest"
          
          # Find latest version
          if latest_path.exists():
              if latest_path.is_symlink():
                  version_dir = latest_path.resolve()
              else:
                  # Windows: read from file
                  with open(latest_path, 'r') as f:
                      version_dir = Path(f.read().strip())
              
              metadata_path = version_dir / "metadata.json"
              if metadata_path.exists():
                  with open(metadata_path, 'r') as f:
                      metadata = json.load(f)
                  print(f"✅ Deployed model verified:")
                  print(f"   Version: {metadata.get('version')}")
                  print(f"   Model: {metadata.get('model_name')}")
                  print(f"   Metrics: {metadata.get('metrics', {})}")
              else:
                  print("⚠️ Metadata not found")
          else:
              print("⚠️ Latest symlink not found")
          EOF

      - name: Run Sample Queries (if RAG available)
        run: |
          echo "⚠️ Sample query test skipped (requires ChromaDB in CI)"
          # In a real scenario, you would run 3 sample queries against the deployed model
        continue-on-error: true
